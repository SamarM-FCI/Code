# -*- coding: utf-8 -*-
"""Copy of SVC_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tVLITBoNCdenoRjyxZTzQmTSMq8V5dqF
"""

from google.colab import drive
drive.mount('/content/drive')

# TF-IDF

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer


Xtr = data['cleanText']
y = data['stance']

VecModel = TfidfVectorizer()
X_Vec_tr = VecModel.fit_transform(Xtr)
X_Vec = pd.DataFrame.sparse.from_spmatrix(X_Vec_tr)

print(f'The new shape for tr is {X_Vec.shape}')

X_train, X_test, y_train, y_test = train_test_split(X_Vec, y, test_size=0.2, random_state=42)

train_X, val_X, train_y, val_y = train_test_split(X_train, y_train, test_size=0.33, random_state=42)
#from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC

#model = Pipeline([('tfidf', TfidfVectorizer()),
 #                    ('clf', LinearSVC()),])

model = LinearSVC()
model.fit(train_X, train_y)


predictions = model.predict(val_X)

from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Assuming val_y is your true labels and predictions are your predicted labels

# Print Classification Report
print("Classification Report:")
print(classification_report(val_y, predictions))

# Calculate and Print ROC-AUC Score
roc_auc = roc_auc_score(val_y, predictions)
print(f"ROC-AUC Score: {roc_auc:.4f}")

# Calculate and Print Accuracy
accuracy = accuracy_score(val_y, predictions)
print(f"Accuracy: {accuracy:.4f}")

# Calculate and Print F1 Score
f1 = f1_score(val_y, predictions)
print(f"F1 Score: {f1:.4f}")

# Calculate and Print Precision
precision = precision_score(val_y, predictions)
print(f"Precision: {precision:.4f}")

# Calculate and Print Recall
recall = recall_score(val_y, predictions)
print(f"Recall: {recall:.4f}")

# Plot ROC Curve
fpr, tpr, thresholds = roc_curve(val_y, predictions)
roc_auc_curve = auc(fpr, tpr)

plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_curve))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

from sklearn import metrics
print(metrics.confusion_matrix(val_y,predictions))

print(metrics.classification_report(val_y,predictions))

#################################################################
X = X_test
y = y_test


pred = model.predict(X)

pred

# Save the NumPy array to a CSV file
import numpy as np
np.savetxt('predictions.csv', pred, delimiter=',', header='Predicted_Label', comments='')

print('Predictions saved to predictions.csv')

from sklearn.metrics import accuracy_score
# Evaluate accuracy
accuracy = accuracy_score(y_test, pred)
print(f'Accuracy on the test set: {accuracy * 100:.2f}%')